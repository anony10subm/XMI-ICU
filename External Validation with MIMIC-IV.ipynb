{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\", palette=\"rocket_r\")\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eICU and MIMIC-IV for 6 hour mortality prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_6.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_6.npy')\n",
    "y_train_eICU  = np.load('Revised Experiments/y_train_static_6.npy')\n",
    "y_test_eICU  = np.load('Revised Experiments/y_test_static_6.npy')\n",
    "\n",
    "X_eICU = np.vstack((X_train_eICU, X_test_eICU))\n",
    "\n",
    "X_train_MIMICIV = np.load('MIMIC-IV/MIMICIV_data/X_train_static_6.npy')\n",
    "X_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/X_test_static_6.npy')\n",
    "y_train_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_train_static_6.npy')\n",
    "y_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_test_static_6.npy')\n",
    "\n",
    "X_MIMICIV = np.vstack((X_train_MIMICIV, X_test_MIMICIV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29851de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eICU = np.vstack((y_train_eICU.reshape(-1, 1), y_test_eICU.reshape(-1, 1)))\n",
    "y_MIMICIV = np.vstack((y_train_MIMICIV.reshape(-1, 1), y_test_MIMICIV.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455cd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eICU = np.hstack((X_eICU, y_eICU.reshape(-1, 1)))\n",
    "X_MIMICIV = np.hstack((X_MIMICIV, y_MIMICIV.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eICU.shape, X_MIMICIV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare age\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 2] < 18) | (X_MIMICIV[:, 2] > 89))[0], axis=0)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 4], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 2], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Age', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare lactate_mean\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 104], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 52], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Lactate', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare SBP_mean\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 65], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 115], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('SBP', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare SBP_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 68], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 152], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('SBP_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Glucose_mean\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 107] > 500))[0], axis=0)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 103], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 107], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Glucose', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Glucose_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 149], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 144], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Glucose_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4653db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare WBC\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 73], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 67], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('WBC', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325efd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare WBC_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 119], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 97], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('WBC_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c660624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANNOT USE THIS ONE, DIFFERENT UNITS\n",
    "\n",
    "# Plot and compare Neutrophils\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 75], color=\"red\", ax=axes[0])\n",
    "#sns.histplot(X_MIMICIV[:, 64], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Neutrophils', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare RDW\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 93], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 62], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('RDW', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eICU = np.delete(X_eICU, np.where(\n",
    "    (X_eICU[:, 139] > 5))[0], axis=0)\n",
    "\n",
    "# Plot and compare RDW_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 139], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 92], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('RDW_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Urea Nitrogen\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 78], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 66], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Urea Nitrogen', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24169db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Urea Nitrogen_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 124], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 96], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Urea Nitrogen_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a135a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_MIMICIV[:, 37] = X_MIMICIV[:, 37] * 5\n",
    "\n",
    "#CANT USE\n",
    "\n",
    "# Plot and compare AST\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 77], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 37], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('AST', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Bicarbonate\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 99], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 39], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Bicarbonate', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and compare Bicarbonate_std\n",
    "f, axes = plt.subplots(1, 2, sharex=True)\n",
    "sns.histplot(X_eICU[:, 145], color=\"red\", ax=axes[0])\n",
    "sns.histplot(X_MIMICIV[:, 72], color=\"green\", ax=axes[1])\n",
    "plt.xlabel('Bicarbonate_std', loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics like mean and std\n",
    "print('Age: ')\n",
    "print(np.mean(X_eICU[:, 4]), np.std(X_eICU[:, 4]))\n",
    "print(np.mean(X_MIMICIV[:, 2]), np.std(X_MIMICIV[:, 2]))\n",
    "print('################################################')\n",
    "print('Lactate: ')\n",
    "print(np.nanmean(X_eICU[:, 104]), np.nanstd(X_eICU[:, 104]))\n",
    "print(np.nanmean(X_MIMICIV[:, 52]), np.nanstd(X_MIMICIV[:, 52]))\n",
    "print('################################################')\n",
    "print('SBP: ')\n",
    "print(np.nanmean(X_eICU[:, 65]), np.nanstd(X_eICU[:, 65]))\n",
    "print(np.nanmean(X_MIMICIV[:, 115]), np.nanstd(X_MIMICIV[:, 115]))\n",
    "print('################################################')\n",
    "print('Glucose: ')\n",
    "print(np.nanmean(X_eICU[:, 103]), np.nanstd(X_eICU[:, 103]))\n",
    "print(np.nanmean(X_MIMICIV[:, 107]), np.nanstd(X_MIMICIV[:, 107]))\n",
    "print('################################################')\n",
    "print('WBC: ')\n",
    "print(np.nanmean(X_eICU[:, 73]), np.nanstd(X_eICU[:, 73]))\n",
    "print(np.nanmean(X_MIMICIV[:, 67]), np.nanstd(X_MIMICIV[:, 67]))\n",
    "print('################################################')\n",
    "print('RDW: ')\n",
    "print(np.nanmean(X_eICU[:, 93]), np.nanstd(X_eICU[:, 93]))\n",
    "print(np.nanmean(X_MIMICIV[:, 62]), np.nanstd(X_MIMICIV[:, 62]))\n",
    "print('################################################')\n",
    "print('Urea Nitrogen: ')\n",
    "print(np.nanmean(X_eICU[:, 78]), np.nanstd(X_eICU[:, 78]))\n",
    "print(np.nanmean(X_MIMICIV[:, 66]), np.nanstd(X_MIMICIV[:, 66]))\n",
    "print('################################################')\n",
    "print('Bicarbonate: ')\n",
    "print(np.nanmean(X_eICU[:, 99]), np.nanstd(X_eICU[:, 99]))\n",
    "print(np.nanmean(X_MIMICIV[:, 39]), np.nanstd(X_MIMICIV[:, 39]))\n",
    "print('################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58496fae",
   "metadata": {},
   "source": [
    "# Train on eICU and validate on MIMIC-IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11377150",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eICU = X_eICU[:, -1]\n",
    "y_MIMICIV = X_MIMICIV[:, -1]\n",
    "\n",
    "X_eICU = X_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_MIMICIV_original = X_MIMICIV.copy()\n",
    "X_MIMICIV = X_MIMICIV[:, [2, 52, 115, 152, 107, 144, 67, 97, 62, 92, 66, 96, 39, 72]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf968751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eICU.shape, X_MIMICIV.shape, y_eICU.shape, X_MIMICIV_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from imblearn.pipeline import Pipeline\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = IterativeImputer(random_state=0, max_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(X_eICU)\n",
    "X_train_res = imp_mean.transform(X_eICU)\n",
    "X_test_res = imp_mean.transform(X_MIMICIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40028f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_eICU, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87346e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "23074/3138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_MIMICIV, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1248/162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the XGBoost model using Bayesian optimisation\n",
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for XGBoost hyperparameters\n",
    "# Depth of tree\n",
    "max_depth = np.linspace(1, 12, 12, endpoint=True)\n",
    "max_depth = [round(x) for x in max_depth]\n",
    "# maximum features\n",
    "n_estimators = list(range(50, 400, 50))\n",
    "# Learning rate\n",
    "lr = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "# Regularisation for imbalanced data\n",
    "max_delta_step = [0, 1, 3, 5, 7, 10]\n",
    "# Gamma for overfitting control\n",
    "min_split_loss = [0, 0.5]\n",
    "# Balance weights for imbalanced classes for AUC\n",
    "scale_pos_weight = [7.353091140854048]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'m__max_depth': max_depth,\n",
    "               'm__n_estimators': n_estimators,\n",
    "               'm__learning_rate': lr,\n",
    "              'm__max_delta_step': max_delta_step,\n",
    "             'm__min_split_loss': min_split_loss,\n",
    "             'm__scale_pos_weight': scale_pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_eICU, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.353091140854048, max_depth = 3, n_estimators = 200,learning_rate = 0.1, min_split_loss = 0.0, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7eaebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0804bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate only on specific subpopulations\n",
    "y_test_men = y_MIMICIV[np.where(X_MIMICIV_original[:,1] == 1)[0]]\n",
    "X_test_men = X_test_res[np.where(X_MIMICIV_original[:,1] == 1)[0], :]\n",
    "# Test results without undersampling or thresholding\n",
    "print('Results for (Men)')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test_men, XGBOOSTmodel.predict_proba(X_test_men)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test_men, XGBOOSTmodel.predict(X_test_men)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test_men, XGBOOSTmodel.predict_proba(X_test_men)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test_men, XGBOOSTmodel.predict(X_test_men), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test_men, XGBOOSTmodel.predict(X_test_men)))\n",
    "print('#################################################')\n",
    "y_test_women = y_MIMICIV[np.where(X_MIMICIV_original[:,1] == 0)[0]]\n",
    "X_test_women = X_test_res[np.where(X_MIMICIV_original[:,1] == 0)[0], :]\n",
    "# Test results without undersampling or thresholding\n",
    "print('Results for (Women)')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test_women, XGBOOSTmodel.predict_proba(X_test_women)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test_women, XGBOOSTmodel.predict(X_test_women)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test_women, XGBOOSTmodel.predict_proba(X_test_women)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test_women, XGBOOSTmodel.predict(X_test_women), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test_women, XGBOOSTmodel.predict(X_test_women)))\n",
    "# Evaluate only on specific subpopulations\n",
    "y_test_caucasian = y_MIMICIV[np.where((X_MIMICIV_original[:,12] == 1).astype(int) | (X_MIMICIV_original[:,13] == 1).astype(int))[0]]\n",
    "X_test_caucasian = X_test_res[np.where((X_MIMICIV_original[:,12] == 1).astype(int) | (X_MIMICIV_original[:,13] == 1).astype(int))[0], :]\n",
    "# Test results without undersampling or thresholding\n",
    "print('Results for Caucasian')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test_caucasian, XGBOOSTmodel.predict_proba(X_test_caucasian)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test_caucasian, XGBOOSTmodel.predict(X_test_caucasian)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test_caucasian, XGBOOSTmodel.predict_proba(X_test_caucasian)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test_caucasian, XGBOOSTmodel.predict(X_test_caucasian), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test_caucasian, XGBOOSTmodel.predict(X_test_caucasian)))\n",
    "print('#################################################')\n",
    "y_test_black_hispanic = y_MIMICIV[np.where(X_MIMICIV_original[:,9] == 1)[0]]\n",
    "X_test_black_hispanic = X_test_res[np.where(X_MIMICIV_original[:,9] == 1)[0], :]\n",
    "# Test results without undersampling or thresholding\n",
    "print('Results for Black/Hispanic')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test_black_hispanic, XGBOOSTmodel.predict_proba(X_test_black_hispanic)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test_black_hispanic, XGBOOSTmodel.predict(X_test_black_hispanic)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test_black_hispanic, XGBOOSTmodel.predict_proba(X_test_black_hispanic)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test_black_hispanic, XGBOOSTmodel.predict(X_test_black_hispanic), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test_black_hispanic, XGBOOSTmodel.predict(X_test_black_hispanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 12 hour prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_12.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_12.npy')\n",
    "y_train_eICU  = np.load('Revised Experiments/y_train_static_12.npy')\n",
    "y_test_eICU  = np.load('Revised Experiments/y_test_static_12.npy')\n",
    "\n",
    "X_eICU = np.vstack((X_train_eICU, X_test_eICU))\n",
    "\n",
    "X_train_MIMICIV = np.load('MIMIC-IV/MIMICIV_data/X_train_static_12.npy')\n",
    "X_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/X_test_static_12.npy')\n",
    "y_train_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_train_static_12.npy')\n",
    "y_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_test_static_12.npy')\n",
    "\n",
    "X_MIMICIV = np.vstack((X_train_MIMICIV, X_test_MIMICIV))\n",
    "\n",
    "y_eICU = np.vstack((y_train_eICU.reshape(-1, 1), y_test_eICU.reshape(-1, 1)))\n",
    "y_MIMICIV = np.vstack((y_train_MIMICIV.reshape(-1, 1), y_test_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "X_eICU = np.hstack((X_eICU, y_eICU.reshape(-1, 1)))\n",
    "X_MIMICIV = np.hstack((X_MIMICIV, y_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "# Process features\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 2] < 18) | (X_MIMICIV[:, 2] > 89))[0], axis=0)\n",
    "\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 107] > 500))[0], axis=0)\n",
    "\n",
    "X_eICU = np.delete(X_eICU, np.where(\n",
    "    (X_eICU[:, 139] > 5))[0], axis=0)\n",
    "\n",
    "y_eICU = X_eICU[:, -1]\n",
    "y_MIMICIV = X_MIMICIV[:, -1]\n",
    "\n",
    "X_eICU = X_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_MIMICIV = X_MIMICIV[:, [2, 52, 115, 152, 107, 144, 67, 97, 62, 92, 66, 96, 39, 72]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62827d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(X_eICU)\n",
    "X_train_res = imp_mean.transform(X_eICU)\n",
    "X_test_res = imp_mean.transform(X_MIMICIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0798d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a344f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_eICU, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "21933/2844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the XGBoost model using Bayesian optimisation\n",
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for XGBoost hyperparameters\n",
    "# Depth of tree\n",
    "max_depth = np.linspace(1, 12, 12, endpoint=True)\n",
    "max_depth = [round(x) for x in max_depth]\n",
    "# maximum features\n",
    "n_estimators = list(range(50, 400, 50))\n",
    "# Learning rate\n",
    "lr = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "# Regularisation for imbalanced data\n",
    "max_delta_step = [0, 1, 3, 5, 7, 10]\n",
    "# Gamma for overfitting control\n",
    "min_split_loss = [0, 0.5]\n",
    "# Balance weights for imbalanced classes for AUC\n",
    "scale_pos_weight = [7.712025316455696]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'m__max_depth': max_depth,\n",
    "               'm__n_estimators': n_estimators,\n",
    "               'm__learning_rate': lr,\n",
    "              'm__max_delta_step': max_delta_step,\n",
    "             'm__min_split_loss': min_split_loss,\n",
    "             'm__scale_pos_weight': scale_pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea46fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_eICU, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a263d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.712025316455696, max_depth = 2, n_estimators = 350,learning_rate = 0.1, min_split_loss = 0.0, max_delta_step = 10, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00347c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 18 hour prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_18.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_18.npy')\n",
    "y_train_eICU  = np.load('Revised Experiments/y_train_static_18.npy')\n",
    "y_test_eICU  = np.load('Revised Experiments/y_test_static_18.npy')\n",
    "\n",
    "X_eICU = np.vstack((X_train_eICU, X_test_eICU))\n",
    "\n",
    "X_train_MIMICIV = np.load('MIMIC-IV/MIMICIV_data/X_train_static_18.npy')\n",
    "X_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/X_test_static_18.npy')\n",
    "y_train_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_train_static_18.npy')\n",
    "y_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_test_static_18.npy')\n",
    "\n",
    "X_MIMICIV = np.vstack((X_train_MIMICIV, X_test_MIMICIV))\n",
    "\n",
    "y_eICU = np.vstack((y_train_eICU.reshape(-1, 1), y_test_eICU.reshape(-1, 1)))\n",
    "y_MIMICIV = np.vstack((y_train_MIMICIV.reshape(-1, 1), y_test_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "X_eICU = np.hstack((X_eICU, y_eICU.reshape(-1, 1)))\n",
    "X_MIMICIV = np.hstack((X_MIMICIV, y_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "# Process features\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 2] < 18) | (X_MIMICIV[:, 2] > 89))[0], axis=0)\n",
    "\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 107] > 500))[0], axis=0)\n",
    "\n",
    "X_eICU = np.delete(X_eICU, np.where(\n",
    "    (X_eICU[:, 139] > 5))[0], axis=0)\n",
    "\n",
    "y_eICU = X_eICU[:, -1]\n",
    "y_MIMICIV = X_MIMICIV[:, -1]\n",
    "\n",
    "X_eICU = X_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_MIMICIV = X_MIMICIV[:, [2, 52, 115, 152, 107, 144, 67, 97, 62, 92, 66, 96, 39, 72]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(X_eICU)\n",
    "X_train_res = imp_mean.transform(X_eICU)\n",
    "X_test_res = imp_mean.transform(X_MIMICIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d84ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2402bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_eICU, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33156e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "20039/2617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94140a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the XGBoost model using Bayesian optimisation\n",
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for XGBoost hyperparameters\n",
    "# Depth of tree\n",
    "max_depth = np.linspace(1, 12, 12, endpoint=True)\n",
    "max_depth = [round(x) for x in max_depth]\n",
    "# maximum features\n",
    "n_estimators = list(range(50, 400, 50))\n",
    "# Learning rate\n",
    "lr = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "# Regularisation for imbalanced data\n",
    "max_delta_step = [0, 1, 3, 5, 7, 10]\n",
    "# Gamma for overfitting control\n",
    "min_split_loss = [0, 0.5]\n",
    "# Balance weights for imbalanced classes for AUC\n",
    "scale_pos_weight = [7.657241115781429]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'m__max_depth': max_depth,\n",
    "               'm__n_estimators': n_estimators,\n",
    "               'm__learning_rate': lr,\n",
    "              'm__max_delta_step': max_delta_step,\n",
    "             'm__min_split_loss': min_split_loss,\n",
    "             'm__scale_pos_weight': scale_pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78200f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_eICU, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.657241115781429, max_depth = 2, n_estimators = 300,learning_rate = 0.1, min_split_loss = 0.0, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e339cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 24 hour prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_24.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_24.npy')\n",
    "y_train_eICU  = np.load('Revised Experiments/y_train_static_24.npy')\n",
    "y_test_eICU  = np.load('Revised Experiments/y_test_static_24.npy')\n",
    "\n",
    "X_eICU = np.vstack((X_train_eICU, X_test_eICU))\n",
    "\n",
    "X_train_MIMICIV = np.load('MIMIC-IV/MIMICIV_data/X_train_static_24.npy')\n",
    "X_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/X_test_static_24.npy')\n",
    "y_train_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_train_static_24.npy')\n",
    "y_test_MIMICIV  = np.load('MIMIC-IV/MIMICIV_data/y_test_static_24.npy')\n",
    "\n",
    "X_MIMICIV = np.vstack((X_train_MIMICIV, X_test_MIMICIV))\n",
    "\n",
    "y_eICU = np.vstack((y_train_eICU.reshape(-1, 1), y_test_eICU.reshape(-1, 1)))\n",
    "y_MIMICIV = np.vstack((y_train_MIMICIV.reshape(-1, 1), y_test_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "X_eICU = np.hstack((X_eICU, y_eICU.reshape(-1, 1)))\n",
    "X_MIMICIV = np.hstack((X_MIMICIV, y_MIMICIV.reshape(-1, 1)))\n",
    "\n",
    "# Process features\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 2] < 18) | (X_MIMICIV[:, 2] > 89))[0], axis=0)\n",
    "\n",
    "X_MIMICIV = np.delete(X_MIMICIV, np.where(\n",
    "    (X_MIMICIV[:, 107] > 500))[0], axis=0)\n",
    "\n",
    "X_eICU = np.delete(X_eICU, np.where(\n",
    "    (X_eICU[:, 139] > 5))[0], axis=0)\n",
    "\n",
    "y_eICU = X_eICU[:, -1]\n",
    "y_MIMICIV = X_MIMICIV[:, -1]\n",
    "\n",
    "X_eICU = X_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_MIMICIV = X_MIMICIV[:, [2, 52, 115, 152, 107, 144, 67, 97, 62, 92, 66, 96, 39, 72]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(X_eICU)\n",
    "X_train_res = imp_mean.transform(X_eICU)\n",
    "X_test_res = imp_mean.transform(X_MIMICIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_eICU, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "17015/2400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f58a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the XGBoost model using Bayesian optimisation\n",
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for XGBoost hyperparameters\n",
    "# Depth of tree\n",
    "max_depth = np.linspace(1, 12, 12, endpoint=True)\n",
    "max_depth = [round(x) for x in max_depth]\n",
    "# maximum features\n",
    "n_estimators = list(range(50, 400, 50))\n",
    "# Learning rate\n",
    "lr = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "# Regularisation for imbalanced data\n",
    "max_delta_step = [0, 1, 3, 5, 7, 10]\n",
    "# Gamma for overfitting control\n",
    "min_split_loss = [0, 0.5]\n",
    "# Balance weights for imbalanced classes for AUC\n",
    "scale_pos_weight = [7.089583333333334]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'m__max_depth': max_depth,\n",
    "               'm__n_estimators': n_estimators,\n",
    "               'm__learning_rate': lr,\n",
    "              'm__max_delta_step': max_delta_step,\n",
    "             'm__min_split_loss': min_split_loss,\n",
    "             'm__scale_pos_weight': scale_pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_eICU, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed4a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.089583333333334, max_depth = 2, n_estimators = 350,learning_rate = 0.1, min_split_loss = 0.0, max_delta_step = 1, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_eICU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_MIMICIV, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_MIMICIV, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45331649",
   "metadata": {},
   "source": [
    "# Tune and test on eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from imblearn.pipeline import Pipeline\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eICU and MIMIC-IV for 6 hour mortality prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_6.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_6.npy')\n",
    "y_train  = np.load('Revised Experiments/y_train_static_6.npy')\n",
    "y_test  = np.load('Revised Experiments/y_test_static_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4daeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_test = X_test_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ac8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "imp_mean = IterativeImputer(random_state=0, max_iter = 10)\n",
    "imp_mean.fit(X_train)\n",
    "X_train_res = imp_mean.transform(X_train)\n",
    "X_test_res = imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the XGBoost model using Bayesian optimisation\n",
    "# Define the hyperparameters you want to sweep through (important it is manual for generalisation)\n",
    "# C for regularisation if doing regression\n",
    "# kernel if doing SVM for example\n",
    "\n",
    "# In this case we are tuning for XGBoost hyperparameters\n",
    "# Depth of tree\n",
    "max_depth = np.linspace(1, 12, 12, endpoint=True)\n",
    "max_depth = [round(x) for x in max_depth]\n",
    "# maximum features\n",
    "n_estimators = list(range(50, 400, 50))\n",
    "# Learning rate\n",
    "lr = [0.001, 0.01, 0.1, 0.3, 0.5, 0.7]\n",
    "# Regularisation for imbalanced data\n",
    "max_delta_step = [0, 1, 3, 5, 7, 10]\n",
    "# Gamma for overfitting control\n",
    "min_split_loss = [0, 0.5]\n",
    "# Balance weights for imbalanced classes for AUC\n",
    "scale_pos_weight = [7.352847471127041]\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {'m__max_depth': max_depth,\n",
    "               'm__n_estimators': n_estimators,\n",
    "               'm__learning_rate': lr,\n",
    "              'm__max_delta_step': max_delta_step,\n",
    "             'm__min_split_loss': min_split_loss,\n",
    "             'm__scale_pos_weight': scale_pos_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed485e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8279ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.352847471127041, max_depth = 10, n_estimators = 200,learning_rate = 0.1, min_split_loss = 0.5, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd54891",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eICU and MIMIC-IV for 12 hour mortality prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_12.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_12.npy')\n",
    "y_train  = np.load('Revised Experiments/y_train_static_12.npy')\n",
    "y_test  = np.load('Revised Experiments/y_test_static_12.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_test = X_test_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "imp_mean = IterativeImputer(random_state=0, max_iter = 10)\n",
    "imp_mean.fit(X_train)\n",
    "X_train_res = imp_mean.transform(X_train)\n",
    "X_test_res = imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on standalone set\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.352847471127041, max_depth = 10, n_estimators = 200,learning_rate = 0.1, min_split_loss = 0.5, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b932aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce067c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eICU and MIMIC-IV for 18 hour mortality prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_18.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_18.npy')\n",
    "y_train = np.load('Revised Experiments/y_train_static_18.npy')\n",
    "y_test = np.load('Revised Experiments/y_test_static_18.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b699a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_test = X_test_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "imp_mean = IterativeImputer(random_state=0, max_iter = 10)\n",
    "imp_mean.fit(X_train)\n",
    "X_train_res = imp_mean.transform(X_train)\n",
    "X_test_res = imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004754aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.352847471127041, max_depth = 10, n_estimators = 200,learning_rate = 0.1, min_split_loss = 0.5, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39271af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5760582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eICU and MIMIC-IV for 24 hour mortality prediction\n",
    "X_train_eICU = np.load('Revised Experiments/X_train_static_24.npy')\n",
    "X_test_eICU  = np.load('Revised Experiments/X_test_static_24.npy')\n",
    "y_train = np.load('Revised Experiments/y_train_static_24.npy')\n",
    "y_test = np.load('Revised Experiments/y_test_static_24.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd699a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]\n",
    "X_test = X_test_eICU[:, [4, 104, 65, 68, 103, 149, 73, 119, 93, 139, 78, 124, 99, 145]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=33)\n",
    "imp_mean = IterativeImputer(random_state=0, max_iter = 10)\n",
    "imp_mean.fit(X_train)\n",
    "X_train_res = imp_mean.transform(X_train)\n",
    "X_test_res = imp_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model you are interested in\n",
    "XGBOOSTmodel = XGBClassifier(use_label_encoder=False)\n",
    "imputer = IterativeImputer(random_state=0, max_iter = 10)\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', XGBOOSTmodel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9753df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with Bayesian optimisation for faster computation of tuning\n",
    "opt = BayesSearchCV(pipeline, param_grid, n_iter=50, cv=cv, verbose=1, refit=False, scoring='roc_auc')\n",
    "opt.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804188be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the following parameter combination being optimal\n",
    "print(\"Best parameter combo:\", opt.best_params_)\n",
    "# Having the following score\n",
    "print(\"Best AUROC:\", opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5619505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XGBOOSTmodel = XGBClassifier(scale_pos_weight = 7.352847471127041, max_depth = 10, n_estimators = 200,learning_rate = 0.1, min_split_loss = 0.5, max_delta_step = 0, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOSTmodel.fit(X_train_res, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddec2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "print('AUROC is:', metrics.roc_auc_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Accuracy is:', metrics.accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Average Precision is:', metrics.average_precision_score(y_test, XGBOOSTmodel.predict_proba(X_test_res)[:,1]))\n",
    "print('Weighted F1 is:', metrics.f1_score(y_test, XGBOOSTmodel.predict(X_test_res), average='weighted'))\n",
    "print('Sensitivity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Balanced accuracy is:', metrics.balanced_accuracy_score(y_test, XGBOOSTmodel.predict(X_test_res)))\n",
    "print('Specificity is:', metrics.recall_score(y_test, XGBOOSTmodel.predict(X_test_res), pos_label=0))\n",
    "print('#################################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
